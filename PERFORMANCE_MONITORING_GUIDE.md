# 🚀 性能监控使用指南

## 📋 概述

本系统已集成完整的性能监控功能，帮助您实时监控显卡状态、模型使用信息和负载均衡策略执行情况。

## 🔍 监控功能概览

### 1. 🚀 负载均衡监控
- **实例选择过程**：详细记录负载均衡策略的执行过程
- **评分系统**：显示每个实例的综合评分和详细指标
- **策略切换**：监控任务类型匹配和回退策略
- **性能统计**：记录选择耗时和成功率

### 2. 📊 GPU状态监控
- **硬件信息**：GPU数量、型号、温度、利用率
- **内存使用**：实时内存使用率和可用内存
- **实例分布**：每个GPU上的实例数量和类型
- **任务统计**：文本翻译和文件翻译任务分布

### 3. ⚡ 翻译性能监控
- **响应时间**：模型推理、实例获取、Tokenization耗时
- **任务统计**：总任务数、成功率、任务类型分布
- **批量处理**：批量翻译的效率和统计信息

## 📝 日志格式说明

### 负载均衡日志
```
🚀 [负载均衡] 开始选择模型实例 - 任务类型: text, 使用CUDA: True
📊 [负载均衡] 可用实例数量: 4
🎯 [负载均衡] 使用text专用实例，数量: 2
🔄 [GPU监控] 已更新GPU内存使用信息
📋 [负载均衡] 开始评估实例状态...
📊 [负载均衡] 实例 cuda_0_0 评分: 85.5 - 槽位: 3/4 (30.0) | 类型匹配: +20 | 响应时间: 45.2ms (13.7) | 成功率: 0.98 (9.8) | GPU内存: 0.75 (1.25)
🏆 [负载均衡] 新最佳实例: cuda_0_0 (评分: 85.5)
✅ [负载均衡] 实例选择完成 - 选择: cuda_0_0, 耗时: 12.3ms
```

### 翻译性能日志
```
🚀 [翻译] 开始翻译单个句子 - 任务类型: text, 使用CUDA: True
📝 [翻译] 源语言: zh_Hans -> 目标语言: khk_Cyrl, 文本长度: 25
✅ [翻译] 获取模型实例完成 - 实例ID: cuda_0_0, 耗时: 15.2ms
⚡ [翻译] 模型推理完成 - 耗时: 234.7ms
```

### 批量翻译日志
```
🚀 [批量翻译] 开始批量翻译 - 任务类型: file, 使用CUDA: True
📝 [批量翻译] 源语言: zh_Hans -> 目标语言: khk_Cyrl, 文本数量: 50
📊 [批量翻译] 总文本长度: 1250 字符
```

## 🛠️ 使用方法

### 1. 实时监控日志
```bash
# 查看实时日志
tail -f logs/app.log

# 过滤负载均衡日志
grep "负载均衡" logs/app.log

# 过滤翻译性能日志
grep "翻译" logs/app.log

# 过滤GPU监控日志
grep "GPU监控" logs/app.log
```

### 2. GPU状态接口
```bash
# 获取GPU状态信息
curl http://localhost:8000/gpu_status

# 返回的JSON包含：
{
  "status": "success",
  "gpus": [
    {
      "gpu_id": 0,
      "name": "Tesla T4",
      "memory_total": 16106127360,
      "memory_used": 1207959552,
      "memory_free": 14898167808,
      "memory_usage_percent": 7.5,
      "temperature": 45,
      "utilization": 15,
      "instances_count": 2,
      "active_instances": 1,
      "text_instances": 1,
      "file_instances": 1
    }
  ],
  "overall_stats": {
    "total_gpus": 1,
    "total_memory_used": 1207959552,
    "total_memory_total": 16106127360,
    "overall_memory_usage_percent": 7.5,
    "total_instances": 2,
    "active_instances": 1,
    "text_instances": 1,
    "file_instances": 1
  }
}
```

### 3. 性能分析工具
```python
# 分析响应时间分布
import re
import matplotlib.pyplot as plt

# 提取响应时间数据
response_times = []
with open('logs/app.log', 'r') as f:
    for line in f:
        match = re.search(r'耗时: ([\d.]+)ms', line)
        if match:
            response_times.append(float(match.group(1)))

# 绘制分布图
plt.hist(response_times, bins=20)
plt.xlabel('响应时间 (ms)')
plt.ylabel('频次')
plt.title('翻译响应时间分布')
plt.show()
```

## 📊 关键指标说明

### 负载均衡评分系统
- **槽位评分 (40%)**：可用槽位越多，评分越高
- **类型匹配 (20%)**：任务类型匹配获得奖励分
- **响应时间 (25%)**：响应时间越短，评分越高
- **成功率 (10%)**：任务成功率影响评分
- **GPU内存 (5%)**：内存使用率越低，评分越高

### 性能阈值建议
- **实例选择时间**：< 50ms (优秀), < 100ms (良好), > 200ms (需要优化)
- **模型推理时间**：< 100ms (优秀), < 300ms (良好), > 500ms (需要优化)
- **GPU内存使用率**：< 70% (安全), < 85% (警告), > 90% (危险)
- **任务成功率**：> 95% (优秀), > 90% (良好), < 85% (需要检查)

## 🔧 故障排查

### 常见问题及解决方案

#### 1. 负载均衡效率低
**症状**：实例选择时间过长，评分差异不大
**解决方案**：
- 检查GPU内存使用情况
- 优化任务类型分布
- 调整评分权重

#### 2. GPU内存不足
**症状**：内存使用率过高，实例创建失败
**解决方案**：
- 减少并发任务数
- 清理未使用的实例
- 重启GPU服务

#### 3. 翻译性能下降
**症状**：响应时间增加，成功率下降
**解决方案**：
- 检查模型实例状态
- 监控GPU温度
- 分析任务分布

## 📈 性能优化建议

### 1. 实例配置优化
```ini
[GPU]
# 根据GPU内存调整并发数
GPU_CONCURRENT_LIMIT = 4  # T4建议4-6

# 任务类型分布
TEXT_TASK_RATIO = 0.6     # 60%文本翻译
FILE_TASK_RATIO = 0.4     # 40%文件翻译
```

### 2. 监控配置优化
```python
# 调整日志级别
logging.getLogger().setLevel(logging.INFO)

# 启用性能监控
ENABLE_PERFORMANCE_MONITORING = True
```

### 3. 定期维护
- 每周清理日志文件
- 每月分析性能趋势
- 每季度优化配置参数

## 🎯 监控最佳实践

1. **实时监控**：使用 `tail -f` 实时观察系统状态
2. **定期检查**：每小时检查GPU状态和性能指标
3. **趋势分析**：记录性能数据，分析长期趋势
4. **告警设置**：设置关键指标的告警阈值
5. **性能报告**：定期生成性能分析报告

## 📞 技术支持

如果在使用过程中遇到问题，请：
1. 查看日志文件获取详细错误信息
2. 使用GPU状态接口检查系统状态
3. 参考故障排查指南
4. 联系技术支持团队

---

*最后更新：2025-08-22*
*版本：v1.0*
