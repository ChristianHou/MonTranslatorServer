version: '3.8'

services:
  # 生产环境GPU版本 - 基于CUDA 12.3.2
  mongolian-translator-gpu-prod:
    build:
      context: .
      dockerfile: Dockerfile.gpu.prod
    container_name: mongolian-translator-gpu-prod
    ports:
      - "8002:8000"
    volumes:
      # 持久化数据目录
      - ./data:/app/data
      - ./cache:/app/cache
      - ./files:/app/files
      - ./logs:/app/logs
      - ./config:/app/config
      - ./models:/app/models
      - ./checkpoints:/app/checkpoints
    environment:
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
      - ENABLE_CUDA=true
      - CUDA_VERSION=12.3.2
      - GPU_MEMORY_LIMIT=16G
      - MAX_TASKS=100
      - MAX_CONCURRENT_TASKS=8
      - MODEL_WARMUP_BATCH_SIZE=4
      - TRANSLATION_TIMEOUT=600
      - FILE_PROCESSING_TIMEOUT=1200
      - ENABLE_MULTI_GPU=true
      - GPU_COUNT=4
      - CUDA_LAUNCH_BLOCKING=0
      - CUDA_CACHE_DISABLE=0
      - CUDA_CACHE_MAXSIZE=2147483648
      - CUDA_DEVICE_MAX_CONNECTIONS=8
      - TORCH_CUDNN_V8_API_ENABLED=1
      - TORCH_CUDNN_BENCHMARK=1
      - TORCH_CUDNN_DETERMINISTIC=0
      - NCCL_DEBUG=INFO
      - NCCL_IB_DISABLE=1
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 32G
        reservations:
          memory: 24G
        reservations:
          devices:
            - driver: nvidia
              count: 4
              capabilities: [gpu]
              options:
                nvidia.com.memory: "16g"
                nvidia.com.compute: "1"
                nvidia.com.mps: "1"
    networks:
      - translator-network
    profiles:
      - t4x4

  # 8张T4配置
  mongolian-translator-gpu-prod-8:
    build:
      context: .
      dockerfile: Dockerfile.gpu.prod
    container_name: mongolian-translator-gpu-prod-8
    ports:
      - "8003:8000"
    volumes:
      - ./data:/app/data
      - ./cache:/app/cache
      - ./files:/app/files
      - ./logs:/app/logs
      - ./config:/app/config
      - ./models:/app/models
      - ./checkpoints:/app/checkpoints
    environment:
      - PYTHONPATH=/app
      - PYTHONUNBUFFERED=1
      - ENABLE_CUDA=true
      - CUDA_VERSION=12.3.2
      - GPU_MEMORY_LIMIT=16G
      - MAX_TASKS=200
      - MAX_CONCURRENT_TASKS=16
      - MODEL_WARMUP_BATCH_SIZE=8
      - TRANSLATION_TIMEOUT=600
      - FILE_PROCESSING_TIMEOUT=1200
      - ENABLE_MULTI_GPU=true
      - GPU_COUNT=8
      - CUDA_LAUNCH_BLOCKING=0
      - CUDA_CACHE_DISABLE=0
      - CUDA_CACHE_MAXSIZE=4294967296
      - CUDA_DEVICE_MAX_CONNECTIONS=16
      - TORCH_CUDNN_V8_API_ENABLED=1
      - TORCH_CUDNN_BENCHMARK=1
      - TORCH_CUDNN_DETERMINISTIC=0
      - NCCL_DEBUG=INFO
      - NCCL_IB_DISABLE=1
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 64G
        reservations:
          memory: 48G
        reservations:
          devices:
            - driver: nvidia
              count: 8
              capabilities: [gpu]
              options:
                nvidia.com.memory: "16g"
                nvidia.com.compute: "1"
                nvidia.com.mps: "1"
    networks:
      - translator-network
    profiles:
      - t4x8

  # 负载均衡器 - Nginx
  nginx:
    image: nginx:alpine
    container_name: mongolian-translator-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - mongolian-translator-gpu-prod
    restart: unless-stopped
    networks:
      - translator-network
    profiles:
      - t4x4
      - t4x8

  # 监控服务 - Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: mongolian-translator-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    networks:
      - translator-network
    profiles:
      - t4x4
      - t4x8

  # 监控服务 - Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: mongolian-translator-grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    restart: unless-stopped
    networks:
      - translator-network
    profiles:
      - t4x4
      - t4x8

networks:
  translator-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  data:
    driver: local
  cache:
    driver: local
  files:
    driver: local
  logs:
    driver: local
  config:
    driver: local
  models:
    driver: local
  checkpoints:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
