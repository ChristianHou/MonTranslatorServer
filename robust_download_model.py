#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¥å£®çš„è’™å¤è¯­ç¿»è¯‘æ¨¡å‹ä¸‹è½½è„šæœ¬
åŒ…å«å¤šç§ä¸‹è½½æ–¹å¼å’Œé”™è¯¯å¤„ç†
"""

import os
import sys
import logging
import time
import subprocess
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('model_download.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

def check_network_connection():
    """æ£€æŸ¥ç½‘ç»œè¿æ¥"""
    import urllib.request
    
    test_urls = [
        "https://huggingface.co",
        "https://www.google.com",
        "https://www.baidu.com"
    ]
    
    for url in test_urls:
        try:
            urllib.request.urlopen(url, timeout=10)
            logger.info(f"âœ… ç½‘ç»œè¿æ¥æ­£å¸¸: {url}")
            return True
        except Exception as e:
            logger.warning(f"âš ï¸  ç½‘ç»œè¿æ¥å¤±è´¥: {url} - {e}")
    
    return False

def install_dependencies():
    """å®‰è£…å¿…è¦çš„ä¾èµ–"""
    try:
        import transformers
        import torch
        import huggingface_hub
        logger.info("âœ… æ‰€æœ‰å¿…è¦çš„åº“å·²å®‰è£…")
        return True
    except ImportError as e:
        logger.info("ğŸ“¦ å®‰è£…å¿…è¦çš„åº“...")
        try:
            subprocess.check_call([
                sys.executable, "-m", "pip", "install", 
                "transformers", "torch", "huggingface_hub", "--upgrade"
            ])
            logger.info("âœ… ä¾èµ–å®‰è£…å®Œæˆ")
            return True
        except Exception as e:
            logger.error(f"âŒ ä¾èµ–å®‰è£…å¤±è´¥: {e}")
            return False

def download_with_huggingface_cli(model_name, cache_dir):
    """ä½¿ç”¨huggingface-cliå‘½ä»¤è¡Œå·¥å…·ä¸‹è½½"""
    try:
        logger.info("ğŸ”„ å°è¯•ä½¿ç”¨huggingface-cliä¸‹è½½...")
        
        # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†huggingface-cli
        try:
            subprocess.run(["huggingface-cli", "--version"], 
                         capture_output=True, check=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            logger.info("ğŸ“¦ å®‰è£…huggingface-cli...")
            subprocess.check_call([
                sys.executable, "-m", "pip", "install", "huggingface_hub[cli]"
            ])
        
        # åˆ›å»ºæœ¬åœ°ç›®å½•
        local_dir = os.path.join(cache_dir, model_name.replace("/", "_"))
        os.makedirs(local_dir, exist_ok=True)
        
        # æ‰§è¡Œä¸‹è½½å‘½ä»¤
        cmd = [
            "huggingface-cli", "download", model_name,
            "--local-dir", local_dir,
            "--cache-dir", cache_dir
        ]
        
        logger.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            logger.info("âœ… huggingface-cliä¸‹è½½æˆåŠŸ")
            return local_dir
        else:
            logger.error(f"âŒ huggingface-cliä¸‹è½½å¤±è´¥: {result.stderr}")
            return None
            
    except Exception as e:
        logger.error(f"âŒ huggingface-cliä¸‹è½½å¼‚å¸¸: {e}")
        return None

def download_with_git_lfs(model_name, cache_dir):
    """ä½¿ç”¨git-lfsä¸‹è½½æ¨¡å‹"""
    try:
        logger.info("ğŸ”„ å°è¯•ä½¿ç”¨git-lfsä¸‹è½½...")
        
        # æ£€æŸ¥gitæ˜¯å¦å®‰è£…
        try:
            subprocess.run(["git", "--version"], capture_output=True, check=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            logger.error("âŒ gitæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…git")
            return None
        
        # åˆ›å»ºæœ¬åœ°ç›®å½•
        local_dir = os.path.join(cache_dir, model_name.replace("/", "_"))
        if os.path.exists(local_dir):
            import shutil
            shutil.rmtree(local_dir)
        
        # å…‹éš†ä»“åº“
        repo_url = f"https://huggingface.co/{model_name}"
        logger.info(f"å…‹éš†ä»“åº“: {repo_url}")
        
        result = subprocess.run([
            "git", "clone", repo_url, local_dir
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            logger.info("âœ… gitå…‹éš†æˆåŠŸ")
            
            # è¿›å…¥ç›®å½•å¹¶æ‹‰å–LFSæ–‡ä»¶
            os.chdir(local_dir)
            subprocess.run(["git", "lfs", "pull"], check=True)
            os.chdir("..")
            
            return local_dir
        else:
            logger.error(f"âŒ gitå…‹éš†å¤±è´¥: {result.stderr}")
            return None
            
    except Exception as e:
        logger.error(f"âŒ git-lfsä¸‹è½½å¼‚å¸¸: {e}")
        return None

def download_with_manual_curl(model_name, cache_dir):
    """ä½¿ç”¨curlæ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶"""
    try:
        logger.info("ğŸ”„ å°è¯•ä½¿ç”¨curlæ‰‹åŠ¨ä¸‹è½½...")
        
        # æ£€æŸ¥curlæ˜¯å¦å¯ç”¨
        try:
            subprocess.run(["curl", "--version"], capture_output=True, check=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            logger.error("âŒ curlæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…curl")
            return None
        
        # åˆ›å»ºæœ¬åœ°ç›®å½•
        local_dir = os.path.join(cache_dir, model_name.replace("/", "_"))
        os.makedirs(local_dir, exist_ok=True)
        
        # æ¨¡å‹æ–‡ä»¶åˆ—è¡¨ï¼ˆå¸¸è§çš„å¿…è¦æ–‡ä»¶ï¼‰
        model_files = [
            "config.json",
            "pytorch_model.bin",
            "tokenizer.json",
            "tokenizer_config.json",
            "special_tokens_map.json",
            "vocab.txt"
        ]
        
        base_url = f"https://huggingface.co/{model_name}/resolve/main"
        
        downloaded_files = []
        for file_name in model_files:
            file_url = f"{base_url}/{file_name}"
            local_file = os.path.join(local_dir, file_name)
            
            logger.info(f"ä¸‹è½½æ–‡ä»¶: {file_name}")
            try:
                result = subprocess.run([
                    "curl", "-L", "-o", local_file, file_url
                ], capture_output=True, text=True)
                
                if result.returncode == 0 and os.path.exists(local_file):
                    downloaded_files.append(file_name)
                    logger.info(f"âœ… {file_name} ä¸‹è½½æˆåŠŸ")
                else:
                    logger.warning(f"âš ï¸  {file_name} ä¸‹è½½å¤±è´¥")
            except Exception as e:
                logger.warning(f"âš ï¸  {file_name} ä¸‹è½½å¼‚å¸¸: {e}")
        
        if len(downloaded_files) >= 3:  # è‡³å°‘éœ€è¦config.json, pytorch_model.bin, tokenizer
            logger.info(f"âœ… æ‰‹åŠ¨ä¸‹è½½å®Œæˆï¼ŒæˆåŠŸä¸‹è½½ {len(downloaded_files)} ä¸ªæ–‡ä»¶")
            return local_dir
        else:
            logger.error("âŒ æ‰‹åŠ¨ä¸‹è½½å¤±è´¥ï¼Œæ–‡ä»¶ä¸å®Œæ•´")
            return None
            
    except Exception as e:
        logger.error(f"âŒ curlæ‰‹åŠ¨ä¸‹è½½å¼‚å¸¸: {e}")
        return None

def download_with_transformers(model_name, cache_dir):
    """ä½¿ç”¨transformersåº“ä¸‹è½½"""
    try:
        logger.info("ğŸ”„ å°è¯•ä½¿ç”¨transformersåº“ä¸‹è½½...")
        
        from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
        from huggingface_hub import snapshot_download
        
        # åˆ›å»ºæœ¬åœ°ç›®å½•
        local_dir = os.path.join(cache_dir, model_name.replace("/", "_"))
        os.makedirs(local_dir, exist_ok=True)
        
        # ä½¿ç”¨snapshot_download
        local_path = snapshot_download(
            repo_id=model_name,
            cache_dir=cache_dir,
            local_dir=local_dir,
            resume_download=True,
            local_files_only=False,
            max_workers=1  # å‡å°‘å¹¶å‘ï¼Œæé«˜ç¨³å®šæ€§
        )
        
        if os.path.exists(local_path):
            logger.info("âœ… transformersä¸‹è½½æˆåŠŸ")
            return local_path
        else:
            logger.error("âŒ transformersä¸‹è½½å¤±è´¥")
            return None
            
    except Exception as e:
        logger.error(f"âŒ transformersä¸‹è½½å¼‚å¸¸: {e}")
        return None

def verify_model_files(model_path):
    """éªŒè¯æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§"""
    if not os.path.exists(model_path):
        return False
    
    required_files = ["config.json", "pytorch_model.bin"]
    optional_files = ["tokenizer.json", "tokenizer_config.json", "vocab.txt"]
    
    # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
    for file_name in required_files:
        file_path = os.path.join(model_path, file_name)
        if not os.path.exists(file_path):
            logger.error(f"âŒ ç¼ºå°‘å¿…éœ€æ–‡ä»¶: {file_name}")
            return False
    
    # æ£€æŸ¥å¯é€‰æ–‡ä»¶
    found_optional = 0
    for file_name in optional_files:
        file_path = os.path.join(model_path, file_name)
        if os.path.exists(file_path):
            found_optional += 1
    
    logger.info(f"âœ… æ¨¡å‹æ–‡ä»¶éªŒè¯é€šè¿‡")
    logger.info(f"  å¿…éœ€æ–‡ä»¶: {len(required_files)}/{len(required_files)}")
    logger.info(f"  å¯é€‰æ–‡ä»¶: {found_optional}/{len(optional_files)}")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    model_name = "Billyyy/mn_nllb_1.3B_continue"
    cache_dir = "./cache"
    
    print("ğŸ¤– å¥å£®çš„è’™å¤è¯­ç¿»è¯‘æ¨¡å‹ä¸‹è½½å·¥å…·")
    print("=" * 60)
    print(f"æ¨¡å‹: {model_name}")
    print(f"ç¼“å­˜ç›®å½•: {cache_dir}")
    print()
    
    # æ£€æŸ¥ç½‘ç»œè¿æ¥
    if not check_network_connection():
        print("âŒ ç½‘ç»œè¿æ¥æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®")
        return
    
    # å®‰è£…ä¾èµ–
    if not install_dependencies():
        print("âŒ ä¾èµ–å®‰è£…å¤±è´¥")
        return
    
    # åˆ›å»ºç¼“å­˜ç›®å½•
    os.makedirs(cache_dir, exist_ok=True)
    
    # å°è¯•å¤šç§ä¸‹è½½æ–¹å¼
    download_methods = [
        ("Transformersåº“", download_with_transformers),
        ("HuggingFace CLI", download_with_huggingface_cli),
        ("Git LFS", download_with_git_lfs),
        ("æ‰‹åŠ¨CURL", download_with_manual_curl)
    ]
    
    model_path = None
    for method_name, download_func in download_methods:
        print(f"\nğŸ”„ å°è¯•æ–¹æ³•: {method_name}")
        try:
            model_path = download_func(model_name, cache_dir)
            if model_path and verify_model_files(model_path):
                print(f"ğŸ‰ ä½¿ç”¨ {method_name} ä¸‹è½½æˆåŠŸï¼")
                break
            else:
                print(f"âš ï¸  {method_name} ä¸‹è½½å¤±è´¥æˆ–æ–‡ä»¶ä¸å®Œæ•´")
        except Exception as e:
            print(f"âŒ {method_name} æ‰§è¡Œå¼‚å¸¸: {e}")
    
    if model_path:
        print(f"\nâœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        print(f"ğŸ“ æœ¬åœ°è·¯å¾„: {model_path}")
        
        # æ›´æ–°é…ç½®æ–‡ä»¶
        config_file = "config/config.ini"
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if model_name not in content:
                lines = content.split('\n')
                for i, line in enumerate(lines):
                    if line.strip() == "[MODEL_LIST]":
                        for j in range(i + 1, len(lines)):
                            if lines[j].strip().startswith('[') and lines[j].strip().endswith(']'):
                                lines.insert(j, f"{model_name} = {model_path}")
                                break
                        break
                
                with open(config_file, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(lines))
                
                print("âœ… é…ç½®æ–‡ä»¶å·²æ›´æ–°")
        
        print("\nğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œ:")
        print("1. é‡å¯ç¿»è¯‘æœåŠ¡å™¨")
        print("2. æµ‹è¯•è’™å¤è¯­ç¿»è¯‘åŠŸèƒ½")
        
    else:
        print("\nğŸ’¥ æ‰€æœ‰ä¸‹è½½æ–¹æ³•éƒ½å¤±è´¥äº†ï¼")
        print("è¯·æ£€æŸ¥:")
        print("1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("2. æ˜¯å¦æœ‰é˜²ç«å¢™æˆ–ä»£ç†é™åˆ¶")
        print("3. ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³")
        print("4. æŸ¥çœ‹è¯¦ç»†æ—¥å¿—: model_download.log")

if __name__ == "__main__":
    main()
